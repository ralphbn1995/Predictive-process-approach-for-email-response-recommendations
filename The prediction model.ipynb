{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tM2K1778j1H8",
   "metadata": {
    "id": "tM2K1778j1H8"
   },
   "source": [
    "# The prediction model\n",
    "Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "kGSXd8n4kR0i",
   "metadata": {
    "id": "kGSXd8n4kR0i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yake in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.4.8)\n",
      "Requirement already satisfied: segtok in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yake) (1.5.11)\n",
      "Requirement already satisfied: networkx in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yake) (2.8.7)\n",
      "Requirement already satisfied: tabulate in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yake) (0.9.0)\n",
      "Requirement already satisfied: click>=6.0 in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yake) (8.1.3)\n",
      "Requirement already satisfied: jellyfish in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yake) (0.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from yake) (1.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click>=6.0->yake) (0.4.5)\n",
      "Requirement already satisfied: regex in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from segtok->yake) (2022.9.13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stanza in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: protobuf in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stanza) (3.19.6)\n",
      "Requirement already satisfied: emoji in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stanza) (2.1.0)\n",
      "Requirement already satisfied: requests in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stanza) (2.28.1)\n",
      "Requirement already satisfied: torch>=1.3.0 in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stanza) (1.12.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stanza) (1.23.4)\n",
      "Requirement already satisfied: six in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stanza) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stanza) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.3.0->stanza) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->stanza) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->stanza) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->stanza) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->stanza) (2.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->stanza) (0.4.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\rbnra\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rbnra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rbnra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecd508a240e4da38b6fb7bd1252a6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 15:09:41 INFO: Downloading default packages for language: en (English) ...\n",
      "2022-10-19 15:09:42 INFO: File exists: C:\\Users\\rbnra\\stanza_resources\\en\\default.zip\n",
      "2022-10-19 15:09:45 INFO: Finished downloading models and saved to C:\\Users\\rbnra\\stanza_resources.\n",
      "2022-10-19 15:09:45 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73c6cc0fed941adaf867538f00337f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 15:09:46 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2022-10-19 15:09:46 INFO: Use device: cpu\n",
      "2022-10-19 15:09:46 INFO: Loading: tokenize\n",
      "2022-10-19 15:09:46 INFO: Loading: ner\n",
      "2022-10-19 15:09:46 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "!pip install yake\n",
    "!pip install stanza\n",
    "\n",
    "import nltk, spacy, csv, re, yake, stanza, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from pprint import pprint\n",
    "import tensorflow as tf\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stanza.download('en')\n",
    "\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,ner')\n",
    "kw_extractor = yake.KeywordExtractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R6QbO2eWj_CJ",
   "metadata": {
    "id": "R6QbO2eWj_CJ"
   },
   "source": [
    "Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0514843",
   "metadata": {
    "id": "e0514843"
   },
   "outputs": [],
   "source": [
    "with open('../Data/dic_allThreads.txt') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "data= []\n",
    "for x in range(0, 500):\n",
    "  first_key = list(json_data.values())[x]\n",
    "\n",
    "  try:\n",
    "    first_ = list(first_key.values())[1]\n",
    "  except IndexError:\n",
    "    first_ = list(first_key.values())[0]\n",
    "  \n",
    "  str_ = ''\n",
    "  if first_[7]:\n",
    "    for row in first_[7]:\n",
    "      if '{' in row[0]:\n",
    "        s = row[0].split('{', 1)[0]\n",
    "        str_ = str_ + ' | ' + s\n",
    "      else:\n",
    "        str_ = str_ + ' | ' + row[0] \n",
    "    data.append(str_.replace(\" \", \"\").replace(\"|\", \" \").strip().replace(\"_\", \"\"))\n",
    "\n",
    "print(data)\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(data)\n",
    "seq = tokenizer.texts_to_sequences(data)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "total_words_dropped = 0\n",
    "\n",
    "for i in seq:\n",
    "    if len(i) > 1:\n",
    "        for index in range(1, len(i)):\n",
    "            X.append(i[:index])\n",
    "            y.append(i[index])\n",
    "    else:\n",
    "        total_words_dropped += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rTVwQo60kFqS",
   "metadata": {
    "id": "rTVwQo60kFqS"
   },
   "source": [
    "Training the recommender model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "220f9c4f",
   "metadata": {
    "id": "220f9c4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 2s 11ms/step - loss: 4.4675 - accuracy: 0.0577\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 4.1339 - accuracy: 0.0721\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.9415 - accuracy: 0.0721\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.8924 - accuracy: 0.0913\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.8667 - accuracy: 0.0913\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.8726 - accuracy: 0.0673\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.8459 - accuracy: 0.0962\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.8450 - accuracy: 0.0913\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.8460 - accuracy: 0.0913\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.8401 - accuracy: 0.0913\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.8349 - accuracy: 0.0913\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.8169 - accuracy: 0.0913\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.7648 - accuracy: 0.0865\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.6959 - accuracy: 0.0913\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.6363 - accuracy: 0.0913\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.5888 - accuracy: 0.0673\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 3.4667 - accuracy: 0.1058\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.3730 - accuracy: 0.1106\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.2625 - accuracy: 0.1298\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 3.1683 - accuracy: 0.1106\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.0833 - accuracy: 0.1635\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.0130 - accuracy: 0.1442\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.9263 - accuracy: 0.1731\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.8582 - accuracy: 0.1635\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.8129 - accuracy: 0.1827\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.7097 - accuracy: 0.1827\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.6231 - accuracy: 0.2067\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.5880 - accuracy: 0.2308\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.5906 - accuracy: 0.2067\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.4923 - accuracy: 0.2404\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.4271 - accuracy: 0.2596\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.3886 - accuracy: 0.2356\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.4367 - accuracy: 0.2163\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.3107 - accuracy: 0.2452\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.2276 - accuracy: 0.2885\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.1785 - accuracy: 0.3077\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.1012 - accuracy: 0.3125\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.0683 - accuracy: 0.3077\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.0334 - accuracy: 0.3462\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.9470 - accuracy: 0.3702\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.8837 - accuracy: 0.3942\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.8500 - accuracy: 0.3942\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.7958 - accuracy: 0.4423\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.7952 - accuracy: 0.4038\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.7053 - accuracy: 0.4327\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.7305 - accuracy: 0.3894\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.6885 - accuracy: 0.4375\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.6667 - accuracy: 0.4519\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.6147 - accuracy: 0.4471\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.6405 - accuracy: 0.4471\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.5890 - accuracy: 0.4471\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.5950 - accuracy: 0.4663\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.5206 - accuracy: 0.4856\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.5013 - accuracy: 0.4808\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.4713 - accuracy: 0.4760\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.4188 - accuracy: 0.5048\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3594 - accuracy: 0.5481\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.3505 - accuracy: 0.5192\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.3168 - accuracy: 0.5625\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.2512 - accuracy: 0.5769\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.2700 - accuracy: 0.5577\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2413 - accuracy: 0.5817\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.2016 - accuracy: 0.6058\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2075 - accuracy: 0.5817\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.1440 - accuracy: 0.6250\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.1352 - accuracy: 0.6010\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.1028 - accuracy: 0.6058\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.0385 - accuracy: 0.6394\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.0418 - accuracy: 0.6298\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.0173 - accuracy: 0.6154\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9702 - accuracy: 0.6587\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.9752 - accuracy: 0.6731\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.9144 - accuracy: 0.6587\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.9572 - accuracy: 0.6538\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9320 - accuracy: 0.6490\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.9356 - accuracy: 0.6346\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9035 - accuracy: 0.6587\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8674 - accuracy: 0.6490\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8469 - accuracy: 0.6587\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8430 - accuracy: 0.6875\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8476 - accuracy: 0.6827\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8236 - accuracy: 0.6538\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8193 - accuracy: 0.6875\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.8056 - accuracy: 0.6875\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.8301 - accuracy: 0.6538\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7984 - accuracy: 0.6923\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7918 - accuracy: 0.6538\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7891 - accuracy: 0.6827\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7854 - accuracy: 0.6827\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7785 - accuracy: 0.6827\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7718 - accuracy: 0.6731\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7557 - accuracy: 0.6731\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7722 - accuracy: 0.6587\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7316 - accuracy: 0.6827\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7330 - accuracy: 0.6587\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7278 - accuracy: 0.6635\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7217 - accuracy: 0.6875\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7260 - accuracy: 0.6779\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7061 - accuracy: 0.6875\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7068 - accuracy: 0.6875\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.7059 - accuracy: 0.6875\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7092 - accuracy: 0.6971\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6936 - accuracy: 0.6971\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6919 - accuracy: 0.6779\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7197 - accuracy: 0.6587\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6870 - accuracy: 0.6779\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6850 - accuracy: 0.6538\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6830 - accuracy: 0.6538\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6750 - accuracy: 0.6875\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6793 - accuracy: 0.6779\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6881 - accuracy: 0.6731\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6809 - accuracy: 0.6779\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7064 - accuracy: 0.6683\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6731 - accuracy: 0.6875\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6853 - accuracy: 0.6827\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6977 - accuracy: 0.6635\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7056 - accuracy: 0.6538\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6996 - accuracy: 0.6827\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7006 - accuracy: 0.6779\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6790 - accuracy: 0.6875\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6676 - accuracy: 0.6923\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6733 - accuracy: 0.6683\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6654 - accuracy: 0.6683\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6700 - accuracy: 0.6827\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6718 - accuracy: 0.6827\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6835 - accuracy: 0.6587\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6530 - accuracy: 0.6827\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6891 - accuracy: 0.6923\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6722 - accuracy: 0.6923\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6934 - accuracy: 0.6827\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6692 - accuracy: 0.6923\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6697 - accuracy: 0.6875\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6650 - accuracy: 0.6779\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6742 - accuracy: 0.6587\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6544 - accuracy: 0.6875\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6584 - accuracy: 0.6827\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6617 - accuracy: 0.6875\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6614 - accuracy: 0.7067\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6603 - accuracy: 0.6875\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6595 - accuracy: 0.6875\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6717 - accuracy: 0.6827\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6729 - accuracy: 0.6538\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6595 - accuracy: 0.6923\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6567 - accuracy: 0.6731\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6585 - accuracy: 0.6875\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6598 - accuracy: 0.6827\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6631 - accuracy: 0.6923\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6833 - accuracy: 0.6587\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6592 - accuracy: 0.6779\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6523 - accuracy: 0.6971\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6587 - accuracy: 0.6779\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6717 - accuracy: 0.6731\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6685 - accuracy: 0.6923\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6554 - accuracy: 0.6971\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6569 - accuracy: 0.6875\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6617 - accuracy: 0.6875\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6518 - accuracy: 0.7067\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6573 - accuracy: 0.6971\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6586 - accuracy: 0.6971\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6494 - accuracy: 0.6779\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6618 - accuracy: 0.6731\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6503 - accuracy: 0.6923\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6466 - accuracy: 0.6827\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6705 - accuracy: 0.6875\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6515 - accuracy: 0.6779\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6506 - accuracy: 0.6875\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6460 - accuracy: 0.6971\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6539 - accuracy: 0.6875\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6510 - accuracy: 0.6635\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6485 - accuracy: 0.6827\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6458 - accuracy: 0.6923\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6387 - accuracy: 0.6971\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6569 - accuracy: 0.6731\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6460 - accuracy: 0.6971\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6476 - accuracy: 0.6779\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6592 - accuracy: 0.6779\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6511 - accuracy: 0.6923\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6517 - accuracy: 0.6731\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6460 - accuracy: 0.6683\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6562 - accuracy: 0.6827\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6484 - accuracy: 0.6779\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6534 - accuracy: 0.6587\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6438 - accuracy: 0.6923\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6382 - accuracy: 0.6923\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6504 - accuracy: 0.6827\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6469 - accuracy: 0.6779\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6511 - accuracy: 0.6827\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6447 - accuracy: 0.6875\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6474 - accuracy: 0.6923\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6530 - accuracy: 0.6827\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6497 - accuracy: 0.6731\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6416 - accuracy: 0.6923\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6483 - accuracy: 0.6923\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6450 - accuracy: 0.6779\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6334 - accuracy: 0.6923\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6490 - accuracy: 0.6731\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6427 - accuracy: 0.6971\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6436 - accuracy: 0.6923\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.6431 - accuracy: 0.6779\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.6566 - accuracy: 0.6875\n"
     ]
    }
   ],
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences(X)\n",
    "y = tf.keras.utils.to_categorical(y)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, 14),\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(128),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(vocab_size, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.02), \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, epochs=100)\n",
    "model.save('nwp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "MjAvX4xg--Sb",
   "metadata": {
    "id": "MjAvX4xg--Sb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 14)          1288      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 100)         46000     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 92)                9292      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 147,080\n",
      "Trainable params: 147,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48f98958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "        output_word = \"\"\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ef800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(\"handle cover deal\", 2, model, 10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Training the recommender Model.ipynb",
   "provenance": [
    {
     "file_id": "10tYvJFZGZkNIAaXL-LuEA9hkJ3yXyNqT",
     "timestamp": 1657087788085
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
